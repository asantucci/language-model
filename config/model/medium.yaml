kv_cache:
  use_kv_cache: false
  q_lora_rank: null
  kv_lora_rank: 128
  rope_head_dim: 128
  nope_head_dim: 128
  v_head_dim: 128
  rope_base: 10000

misc:
  init_weight_std: 0.02
  rms_norm_eps: 1e-6
  device: cuda

model:
  d_model: 2048
  nheads: 8
  num_layers: 10
  max_position_embeddings: 4096
  dropout: 0.1
  vocab_size: 50257

moe:
  num_shared_experts: 1
  num_routed_experts: 3
  moe_hidden_dimension: 4096
  mlp_hidden_dimension: 4096
  topk: 2
  expert_load_balance_factor: 0.01
  topk_norm_epsilon: 1e-9
  normalized_moe_gates: true
  first_k_dense_replace: 1
  disable_moe: false

rope:
  head_dim: 128
  base: 10000
  