kv_cache:
  use_kv_cache: false
  q_lora_rank: 0
  kv_lora_rank: 0
  rope_head_dim: 16
  nope_head_dim: 0
  v_head_dim: 16
  rope_base: 10000

misc:
  init_weight_std: 0.02
  rms_norm_eps: 1e-6
  device: cuda

model:
  d_model: 64
  nheads: 4
  num_layers: 2
  max_position_embeddings: 64
  dropout: 0.0
  vocab_size: 128

moe:
  num_shared_experts: 2
  num_routed_experts: 2
  moe_hidden_dimension: 256
  mlp_hidden_dimension: 256
  topk: 2
  expert_load_balance_factor: 0.01
  topk_norm_epsilon: 1e-9
  normalized_moe_gates: true
  first_k_dense_replace: 4
  disable_moe: false

rope:
  head_dim: 16
  base: 10000
  